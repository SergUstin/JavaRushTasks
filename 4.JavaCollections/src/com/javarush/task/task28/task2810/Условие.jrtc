taskKey="com.javarush.task.task28.task2810.big08"\n\nAggregator (8)

Запусти снова программу в дебаг моде.
Скопируй полученное значение document.html() в созданный ранее html файл.
Отформатируй его и найди теги с вакансиями.

Почитай в Сообществе дополнительный материал к лекции про селекторы атрибута.

ВНИМАНИЕ: ОСОБЕННОСТИ ТЕСТИРОВАНИЯ!
HTML код странички ХэдХантера может меняться, чтобы эта задача продолжила работать стабильно не меняя тесты
воспользуйся закешированной версией https://javarush.com/testdata/big28data.html
Это только для этого пункта, в следующих заданиях используй реальные страницы.

1. В классе HHStrategy создай protected метод Document getDocument(String searchString, int page) throws IOException.

2. Реализуй следующую логику метода getVacancies в классе HHStrategy:
2.1. Подключись к закешированной страничке ХэдХантера используя метод getDocument, нумерация начинается с 0.
2.2. Получи список элементов с атрибутом по имени &quot;data-qa&quot; и значением &quot;vacancy-serp__vacancy&quot;. Должно быть до 20 вакансий на странице.
2.3. Если данные в списке из п.2.2 есть, то для каждого элемента:
2.3.1. создать вакансию и заполнить все ее данные, получив данные из текущего элемента.
Если тег с зарплатой присутствует, то заполнить и поле salary, иначе инициализировать поле пустой строкой.
site и url нужно взять из атрибута со значением &quot;vacancy-serp__vacancy-title&quot;.
2.4. Выполнить п.2.1-2.3 для следующей страницы ХэдХантера.
2.5. Если закончились страницы с вакансиями, то выйти из цикла.

Исключения игнорировать.
Все вакансии добавить в общий список и вернуть в качестве результата метода.

Подсказка по зарплате:
Поиграйся с URL_FORMAT, добавь туда еще один параметр, чтобы получить вакансии с зарплатами.
Проанализируй полученный html и найди тег для зарплаты.
Не забудь потом вернуть значение URL_FORMAT обратно.


Требования:
1.	В классе HHStrategy создай protected метод getDocument(String searchString, int page). Перенеси туда логику по получению объекта html-страницы Document.
2.	Метод getVacancies класса HHStrategy должен получать содержимое страниц с помощью метода getDocument. Начни с 0 страницы.
3.	Из объекта Document получи список html-элементов с атрибутом по имени &quot;data-qa&quot; и значением &quot;vacancy-serp__vacancy&quot;. Для каждого элемента создай объект вакансии и добавь его в возвращающий методом список.
4.	Нужно последовательно обработать все страницы результатов поиска. Как только страницы с вакансиями закончатся, прерви цикл и верни список найденных вакансий.
5.	У каждой вакансии должно быть заполнено поле title полученными из html-элемента данными о названии вакансии.
6.	У каждой вакансии должно быть заполнено поле url полученной из html-элемента ссылкой на вакансию.
7.	У каждой вакансии должно быть заполнено поле city полученными из html-элемента данными о городе.
8.	У каждой вакансии должно быть заполнено поле companyName полученными из html-элемента данными о компании.
9.	У каждой вакансии должно быть заполнено поле siteName значением сайта, на котором вакансия была найдена.
10.	Поле salary у вакансии должно быть заполнено, если в html-элементе присутствовал тег с зарплатой. Иначе поле должно быть инициализировано пустой строкой.
11.	Если ты менял значение поля URL_FORMAT, не забудь вернуть его обратно.


Aggregator (8)

Чтобы сайт поиска работы знал, кто к нему коннектится, проставим Request Headers в наш запрос.

Для разработчиков созданы инструменты, которые показывают различную информацию про запросы.
Я расскажу тебе про два инструмента.

***Chrome****
1. В браузере Хром пойди в Меню - Инструменты - Инструменты разработчика, или нажми Ctrl+Shift+I
2. В браузерной строке набери URL https://grc.ua/search/vacancy?text=java+Kiev или https://hh.ru/search/vacancy?text=java+Kiev
3. Перейди на табу Network(Сеть), запрашиваемый URL должен быть в самом верху.
У него метод отправки данных GET (еще есть POST), статус 200(успешно)
4. Выбери его, откроется информация о страничке.
5. Найди Request Headers(Заголовки запроса)

***FireFox***
1. В браузере FireFox пойди в Меню - Веб-разработка - Инструменты разработчика, или нажми Ctrl+Shift+I
2. В браузерной строке набери URL https://grc.ua/search/vacancy?text=java+Kiev или https://hh.ru/search/vacancy?text=java+Kiev
3. Перейди на табу Network(Сеть), запрашиваемый URL должен быть в самом верху.
4. Выбери его, откроется информация о страничке.
5. Найди Request Headers(Заголовки запроса)

Добавь в коннекшен к урлу сайта поиска работы userAgent и referrer.



Aggregator (8)

1. В папке куда ты скачал либу org.jsoup:jsoup:1.9.2 из maven репозитория, найди jar-архив jsoup-1.9.2.jar или jsoup-1.9.2-sources.jar.
В нем найди пакет examples, посмотри классы в этом пакете.

2. По аналогии с реализацией в примерах кода jsoup - реализуй коннекшен к урлу сайта поиска работы методом GET.
Это нужно сделать в методе getVacancies класса HHStrategy.
Подсказка: получится объект класса Document.

3. Поставь брекпоинт сразу после коннекшена. Запусти программу в дебаг моде.
Скопируй полученное значение document.html() в буфер.

4. Создай файл с расширением html где-то в корне проекта.
Вставь содержимое буфера в этот файл и отформатируй его Ctrl+Alt+L, IDEA умеет форматировать HTML.
Ура! Это код страницы HTML :)

5. Реализуй в вакансии (Vacancy) методы equals/hashCode.
Alt+Insert - equals() and hashCode().



Aggregator (8)

1. Добавь в интерфейс Strategy метод getVacancies(String searchString), который будет возвращать список вакансий.

2. Поправь ошибки в классе HHStrategy.

3. Вернись в метод getJavaVacancies класса Provider, реализуй его логику из расчета, что всех данных хватает.

4. Давай попробуем запустить и посмотреть, как работает наша программа.
В методе main вместо вывода на экран напиши controller.scan();
Воспользуйся подсказкой IDEA и создай метод.
Внутри метода пройдись по всем провайдерам и собери с них все вакансии, добавь их в список. Выведи количество вакансий в консоль.

5. Исправь NPE, если появляется это исключение (поставь заглушку, например Collections.emptyList()).



Aggregator (8)

Открой сайт поиска работы - https://grc.ua/ и https://hh.ru/
В строке поиска набери &quot;java Kiev&quot;, снизу перейди на вторую страницу, т.к. урлы часто отличаются на первой странице и далее.
У меня получилась такая ссылка:
https://grc.ua/search/vacancy?text=java+Kiev&amp;page=1 и https://hh.ru/search/vacancy?text=java+Kiev&amp;page=1
Из этого следует, что
1) если тебе нужно будет фильтровать по городу, то ты добавишь его после слова java, разделив их знаком &quot;+&quot;,
2) нумерация страниц начинается с 0.

Итак, ссылка будет примерно такой:
https://grc.ua/search/vacancy?text=java+ADDITIONAL_VALUE&amp;page=PAGE_VALUE

1. Из полученной ссылки в HHStrategy создай приватную строковую константу URL_FORMAT, которая будет передаваться в String.format().
В результате подстановки константы URL_FORMAT в String.format(URL_FORMAT, &quot;Kiev&quot;, 3) с такими параметрами, результат должен быть таким:
&quot;https://grc.ua/search/vacancy?text=java+Kiev&amp;page=3&quot;
или
&quot;https://hh.ru/search/vacancy?text=java+Kiev&amp;page=3&quot;
Для этого скопируй ссылку в код и нажми на ней нужную комбинацию клавиш.
Ctrl+Alt+C(Constant) - создание констант,
Ctrl+Alt+M(Method) - создание методов,
Ctrl+Alt+V(Variable) - создание переменных.

2. Тебе нужно программно получить исходный код страницы. Это HTTP запрос. Тебе понадобится Java HTML Parser.
Хороший парсер jsoup, будешь использовать его. Мы будем использовать версию 1.9.2.

3. Скачать и подключить новые либы можно так:
В IDEA открой Project Structure (в меню File).
Слева выбери Project Settings -&gt; Libraries, в окошке справа сверху нажми &quot;+&quot;.
Выбери &quot;From Maven...&quot;. В окне поиска введи &quot;org.jsoup:jsoup:1.9.2&quot;. Поставь галочку на &quot;Download to:&quot; и выбери куда скачать либу.
Также поставь галочки на &quot;Transitive dependencies&quot;, &quot;Sources&quot;.
В окне Choose Modules выбери модуль 4.JavaCollections.

4. Прочитай дополнительный материал к лекции в Сообществе.
https://javarush.ru/groups/posts/2007-legkiy-parsing-html-s-pomojshjhju-jsoup
https://javarush.ru/groups/posts/1086-3-primera-kak-razobratjh-html-fayl-v-java-ispoljhzuja-jsoup



Aggregator (8)

Начиная с этого задания ты начнешь писать логику получения данных с сайта.
Эта логика будет полностью сосредоточена в классах, реализующих интерфейс Strategy.

Провайдер в данном случае выступает в качестве контекста, если мы говорим о паттерне Стратегия.
В провайдере должен быть метод, который будет вызывать метод стратегии для выполнения главной операции.
Этот метод будет возвращать все java вакансии с выбранного сайта (ресурса).

1. В корне задачи создай пакет vo (value object), в котором создай класс Vacancy.
Этот класс будет хранить данные о вакансии.

2. В Provider создай публичный метод List&lt;Vacancy&gt; getJavaVacancies(String searchString). Оставь пока метод пустым.

3. Что есть у вакансии?
Название, зарплата, город, название компании, название сайта, на котором вакансия найдена, ссылка на вакансию.
В классе Vacancy создай соответствующие приватные строковые поля: title, salary, city, companyName, siteName, url.

4. Создай геттеры и сеттеры для всех полей класса Vacancy.

5. В пакете model создай класс HHStrategy, реализующий интерфейс Strategy.
Этот класс будет реализовывать конкретную стратегию работы с сайтом поиска работы (https://grc.ua/ и https://hh.ru/).



